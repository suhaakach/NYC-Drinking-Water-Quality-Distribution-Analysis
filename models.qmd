
# Modelling

```{python}
def check_stationarity(series):
    '''Check stationarity of column using Augmented Dickey-Fuller test'''
    result = adfuller(series)
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')
    if result[1] <= 0.05:
        print('The series is stationary.')
        print()
    else:
        print('The series is not stationary.')
        print()

# check stationarities
for col in ['chlorine', 'turbidity', 'coliform', 'ecoli']:
    print(f'Checking stationarity for {col}')
    check_stationarity(data[col])
```

```{python}
# split into training and testing
train_size = int(len(data) * 0.7)

data_train = data[:train_size]
data_test = data[train_size:]
```

```{python}
model = VAR(data_train)
```

```{python}
lag_results = {}

# iterate through range of possible lags
for i in range(1, 31):
  result = model.fit(i)
  lag_results[i] = {
    'AIC': result.aic,
    'BIC': result.bic,
    'HQIC': result.hqic,
    }

# find best lag by metric
best_aic = min(lag_results, key = lambda x: lag_results[x]['AIC'])
best_bic = min(lag_results, key = lambda x: lag_results[x]['BIC'])
best_hqic = min(lag_results, key = lambda x: lag_results[x]['HQIC'])

print(f'Best lag by AIC: {best_aic}')
print(f'Best lag by BIC: {best_bic}')
print(f'Best lag by HQIC: {best_hqic}')
```

```{python}
lags = list(lag_results.keys())
aic_values = [lag_results[lag]['AIC'] for lag in lags]
bic_values = [lag_results[lag]['BIC'] for lag in lags]
hqic_values = [lag_results[lag]['HQIC'] for lag in lags]

# plot AIC, BIC, and HQIC for range of lags
plt.plot(lags, aic_values, label='AIC', marker='o')
plt.plot(lags, bic_values, label='BIC', marker='o')
plt.plot(lags, hqic_values, label='HQIC', marker='o')
plt.xlabel('Lag Order')
plt.ylabel('Information Criterion')
plt.title('Lag Order Selection (Custom Range)')
plt.legend()
plt.show()
```

```{python}
# fit model
results = model.fit(maxlags = 27)

# create predictions
forecast_input = data_train.values[-results.k_ar:]
forecast = results.forecast(forecast_input, steps = len(data_test))
forecast_df = pd.DataFrame(forecast, index = data_test.index, 
                                        columns = data_test.columns)
```

```{python}
mae = mean_absolute_error(data_test, forecast_df)
rmse = mean_squared_error(data_test, forecast_df, squared = False)

print(f'MAE: {mae}')
print(f'RMSE: {rmse}')
```

```{python}
for col in data_test.columns:
  actual = data_test[col]
  pred = forecast_df[col]

  print(f'R-squared for {col} on test set: {r2_score(actual, pred):.4f}')
```


```{python}
merged_df['ecoli'].mean()

# create response variable based off national standards
merged_df['compliant'] = (
  (merged_df['chlorine'] > 0.2) & (merged_df['chlorine'] < 1.0) & 
  (merged_df['ecoli'] <= 0) &  # instead of '==' use '<=' or '<' for more flexibility
  (merged_df['turbidity'] < 0.3) & 
  (merged_df['coliform'] < 2.67)
).astype(int)


```

```{python}
# get dummy variables
model_data = pd.get_dummies(merged_df, dtype=int)
model_data.drop(columns=['zip code'], inplace=True)

X = model_data.drop(columns=['compliant'])
y = model_data['compliant']

# Check the class distribution before resampling
print(y.value_counts())

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=0)
X_resampled, y_resampled = smote.fit_resample(X, y)

```

```{python}
from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
# Split the resampled data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=4188)

# Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Fit the Logistic Regression model
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)

# Get predicted probabilities for the compliant class (class 1)
y_pred_prob = logreg.predict_proba(X_test)[:, 1]

# Adjust threshold and evaluate
y_pred_adjusted = (y_pred_prob > 0.3).astype(int)

print('Accuracy:', accuracy_score(y_test, y_pred_adjusted))
print('Precision:', precision_score(y_test, y_pred_adjusted))
print('Recall:', recall_score(y_test, y_pred_adjusted))
print('F1 Score:', f1_score(y_test, y_pred_adjusted))

cm = confusion_matrix(y_test, y_pred_adjusted)
print(cm)
```

## Model Fitting & Evaluation

```{python}
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Define the model
logreg = LogisticRegression(max_iter=1000)

# Define the parameter grid for ElasticNet (combining L1 and L2)
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'penalty': ['elasticnet'],
    'l1_ratio': [0.1, 0.5, 0.9],  # Ratio between L1 and L2 (0 = L2, 1 = L1)
    'solver': ['saga']  # 'saga' solver supports elasticnet
}

# Grid search with cross-validation
grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best parameters and score
print(f"Best parameters: {grid_search.best_params_}")
print(f"Best cross-validation score (F1): {grid_search.best_score_}")

# Get the best estimator and evaluate
best_logreg = grid_search.best_estimator_
y_pred_prob = best_logreg.predict_proba(X_test)[:, 1]
y_pred_adjusted = (y_pred_prob > 0.3).astype(int)

# Print evaluation metrics
print('Accuracy:', accuracy_score(y_test, y_pred_adjusted))
print('Precision:', precision_score(y_test, y_pred_adjusted))
print('Recall:', recall_score(y_test, y_pred_adjusted))
print('F1 Score:', f1_score(y_test, y_pred_adjusted))

```

```{python}
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

# Create a learning curve
train_sizes, train_scores, test_scores = learning_curve(
    best_logreg, X_train, y_train, cv=5, n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10), scoring='f1')

# Calculate the mean and standard deviation for plotting
train_mean = train_scores.mean(axis=1)
train_std = train_scores.std(axis=1)
test_mean = test_scores.mean(axis=1)
test_std = test_scores.std(axis=1)

# Plot the learning curve
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, color='blue', label='Training score')
plt.plot(train_sizes, test_mean, color='red', label='Cross-validation score')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='red')
plt.title("Learning Curve (Logistic Regression)")
plt.xlabel("Number of Training Samples")
plt.ylabel("F1 Score")
plt.legend(loc="best")
plt.show()

```

```{python}
import pandas as pd

# Get the best logistic regression model from grid search
best_logreg = grid_search.best_estimator_

# Get the coefficients and feature names
coefficients = best_logreg.coef_[0]
feature_names = X.columns

# Create a DataFrame to show the feature importance
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefficients,
    'Absolute Coefficient': abs(coefficients)
})

# Sort the features by absolute coefficient value (importance)
feature_importance_df = feature_importance_df.sort_values(by='Absolute Coefficient', ascending=False)

# Display the feature importance
print(feature_importance_df)

# Plot the feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Absolute Coefficient'], color='skyblue')
plt.xlabel('Absolute Coefficient')
plt.title('Feature Importance (Logistic Regression)')
plt.gca().invert_yaxis()  # Invert y-axis to show the most important features at the top
plt.show()
```
